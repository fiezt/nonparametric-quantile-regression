{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from natsort import natsorted\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(solar_dir):\n",
    "    \"\"\"Load the initial data into dataframes.\n",
    "    \n",
    "    :param solar_dir: Directory to the solar data.\n",
    "    :return benchmarks, predictors, train, solutions: List ordered by the task \n",
    "    number of dataframes containing the benchmark results, the predictor \n",
    "    variables, the training labels, and the solution respectively.\n",
    "    \"\"\"\n",
    "    \n",
    "    benchmarks = {}\n",
    "    predictors = {}\n",
    "    train = {}\n",
    "    solutions = {}\n",
    "    \n",
    "    # Walk through directories to get the different files.\n",
    "    for root, dirs, files in os.walk(solar_dir):\n",
    "        for fname in files:\n",
    "            if '.csv' in fname:\n",
    "                if 'benchmark' in fname:\n",
    "                    benchmarks[fname.split('.')[0]] = pd.read_csv(os.path.join(root, fname))\n",
    "                elif 'predictors' in fname:\n",
    "                    predictors[fname.split('.')[0]] = pd.read_csv(os.path.join(root, fname))\n",
    "                elif 'train' in fname:\n",
    "                    train[fname.split('.')[0]] = pd.read_csv(os.path.join(root, fname))\n",
    "                elif 'Solution' in fname:\n",
    "                    solutions[fname.split('.')[0]] = pd.read_csv(os.path.join(root, fname))   \n",
    "\n",
    "    # Number of sets provided.\n",
    "    N = len(train)\n",
    "    \n",
    "    # Testing data.\n",
    "    benchmarks = natsorted(benchmarks.items(), key=lambda x: x[0])\n",
    "    benchmarks = [item[1] for item in benchmarks]\n",
    "\n",
    "    # Given features.\n",
    "    predictors = natsorted(predictors.items(), key=lambda x: x[0])\n",
    "    predictors = [item[1] for item in predictors]\n",
    "\n",
    "    # Training labels.\n",
    "    train = natsorted(train.items(), key=lambda x: x[0])\n",
    "    train = [item[1] for item in train]\n",
    "\n",
    "    # Solution to the test set.\n",
    "    solutions = natsorted(solutions.items(), key=lambda x: x[0])\n",
    "    solutions = [item[1] for item in solutions]\n",
    "\n",
    "    for i in range(N):\n",
    "        predictors[i]['TIMESTAMP'] =  pd.to_datetime(predictors[i]['TIMESTAMP'], format='%Y%m%d %H:%M')\n",
    "        benchmarks[i]['TIMESTAMP'] =  pd.to_datetime(benchmarks[i]['TIMESTAMP'], format='%Y%m%d %H:%M')\n",
    "        train[i]['TIMESTAMP'] =  pd.to_datetime(train[i]['TIMESTAMP'], format='%Y%m%d %H:%M')\n",
    "        \n",
    "    return benchmarks, predictors, train, solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize_data(predictors, train, solar_dir, i):\n",
    "    \"\"\"Create the featurized data from the predictors and add training labels.\n",
    "    \n",
    "    :param predictors: List of dataframes containing the predictor information \n",
    "    for each task.\n",
    "    :param train: List of dataframes containing the training label for each task.\n",
    "    :param solar_dir: Directory to save the featurized solar data to.\n",
    "    :param i: Task number to create the featurized data for.\n",
    "    \n",
    "    :return: Write the featurized data to files.\n",
    "    \"\"\"\n",
    "    \n",
    "    cols = ['ZONEID', 'TIMESTAMP', 'VAR1', 'VAR2', 'VAR3', 'VAR4', 'VAR5', 'VAR6', \n",
    "            'VAR7', 'VAR8', 'VAR9', 'VAR10', 'VAR11', 'VAR12']\n",
    "    \n",
    "    if 'POWER' in predictors[i].columns:\n",
    "        del predictors[i]['POWER']\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    predictors[i].columns = cols\n",
    "\n",
    "    # Wind speed magnitude.\n",
    "    predictors[i]['VAR13'] = np.sqrt(predictors[i]['VAR6']**2 + predictors[i]['VAR7']**2)    \n",
    "\n",
    "    # Total cloud cover x surface solar radiation.\n",
    "    predictors[i]['VAR14'] = predictors[i]['VAR5'] * predictors[i]['VAR9']\n",
    "\n",
    "    # Total cloud cover x relative humidity.\n",
    "    predictors[i]['VAR15'] = predictors[i]['VAR5'] * predictors[i]['VAR4']\n",
    "\n",
    "    # Freezing temperature flag. Note that freezing in kelvin is 273.15.\n",
    "    predictors[i]['VAR16'] = predictors[i]['VAR8'] < 273.15 \n",
    "    predictors[i]['VAR16'] = predictors[i]['VAR16'].astype(int)\n",
    "\n",
    "    # Precipitation flag. Total precipitation > 0.\n",
    "    predictors[i]['VAR17'] = predictors[i]['VAR12'] > 0 \n",
    "    predictors[i]['VAR17'] = predictors[i]['VAR17'].astype(int)\n",
    "\n",
    "    # Snow flag. Freezing flag times precipitation flag.\n",
    "    predictors[i]['VAR18'] = predictors[i].apply(lambda x: x['VAR16'] * x['VAR17'], axis=1)\n",
    "\n",
    "    # Differential surface pressure.\n",
    "    predictors[i]['VAR19'] = predictors[i]['VAR3'] - predictors[i]['VAR3'].shift(1)\n",
    "\n",
    "    # Differential total cloud cover.\n",
    "    predictors[i]['VAR20'] = predictors[i]['VAR5'] - predictors[i]['VAR5'].shift(1)\n",
    "\n",
    "    # Converting the temperature in kelvin to celsius.\n",
    "    predictors[i]['CELSIUS_TEMP'] = predictors[i]['VAR8'] - 273.15\n",
    "\n",
    "    # Wind chill index. \n",
    "    predictors[i]['VAR_21'] = (10*np.sqrt(predictors[i]['VAR13']) - predictors[i]['VAR13'] + 10.5) \\\n",
    "                             * (33 - predictors[i]['CELSIUS_TEMP'])\n",
    "\n",
    "    # Solar model temperature.\n",
    "    predictors[i]['VAR_22'] = predictors[i]['CELSIUS_TEMP'] + np.exp(-3.473 - 0.0594*predictors[i]['VAR13'])\n",
    "\n",
    "    # Maximum solar power output for each day and each zone.\n",
    "    predictors[i]['VAR23'] = pd.Series(np.nan, index=predictors[i].index)    \n",
    "    predictors[i]['VAR24'] = pd.Series(np.nan, index=predictors[i].index)    \n",
    "    predictors[i]['VAR25'] = pd.Series(np.nan, index=predictors[i].index)    \n",
    "\n",
    "    predictors[i]['DATE'] = predictors[i]['TIMESTAMP'].dt.date    \n",
    "    train[i]['DATE'] = train[i]['TIMESTAMP'].dt.date\n",
    "    max_power = train[i].groupby(['ZONEID','DATE']).max()\n",
    "\n",
    "    for date in train[i]['DATE'].unique():\n",
    "        predictors[i].loc[predictors[i]['DATE'] == date, 'VAR23'] = max_power.ix[1,date]['POWER']\n",
    "        predictors[i].loc[predictors[i]['DATE'] == date, 'VAR24'] = max_power.ix[2,date]['POWER']\n",
    "        predictors[i].loc[predictors[i]['DATE'] == date, 'VAR25'] = max_power.ix[3,date]['POWER']\n",
    "\n",
    "    # Cos(day/365 * 2 *pi).\n",
    "    predictors[i]['VAR26'] = np.cos((predictors[i]['TIMESTAMP'].dt.dayofyear * 2 * np.pi)/365.)\n",
    "\n",
    "    # Cos(day/365 * 2 *pi).\n",
    "    predictors[i]['VAR27'] = np.sin((predictors[i]['TIMESTAMP'].dt.dayofyear * 2 * np.pi)/365.)\n",
    "\n",
    "    # Sin(hour/24 * 2 *pi).\n",
    "    predictors[i]['VAR28'] = np.cos((predictors[i]['TIMESTAMP'].dt.hour * 2 * np.pi)/24.)\n",
    "\n",
    "    # Sin(hour/24 * 2 *pi).\n",
    "    predictors[i]['VAR29'] = np.sin((predictors[i]['TIMESTAMP'].dt.hour * 2 * np.pi)/24.)\n",
    "\n",
    "    # Getting the power for each timestamp available in the training data.\n",
    "    train[i] = train[i][['ZONEID', 'TIMESTAMP', 'POWER']]\n",
    "    predictors[i] = pd.merge(predictors[i], train[i], how='left', on=['TIMESTAMP', 'ZONEID'])\n",
    "\n",
    "    del predictors[i]['DATE']\n",
    "    del predictors[i]['CELSIUS_TEMP']\n",
    "\n",
    "    predictors[i].to_csv(os.path.join(solar_dir + '/Task ' + str(i+1), 'features' + str(i+1) + '.csv'), sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Load the data, create and write the featurized data to files.\"\"\"\n",
    "    \n",
    "    curr_dir = os.getcwd()\n",
    "    data_dir = curr_dir + '/../Data'\n",
    "    solar_dir = data_dir + '/Solar'\n",
    "    wind_dir = data_dir + '/Wind'\n",
    "    price_dir = data_dir + '/Price'\n",
    "    load_dir = data_dir + '/Load'\n",
    "    \n",
    "    benchmarks, predictors, train, solutions = load_data(solar_dir)\n",
    "    \n",
    "    # Create the featurized data for each task in parallel.\n",
    "    func = partial(featurize_data, predictors, train, solar_dir)\n",
    "    multiprocessing.Pool().map(func, range(len(predictors)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
