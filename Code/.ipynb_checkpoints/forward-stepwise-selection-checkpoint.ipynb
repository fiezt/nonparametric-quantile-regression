{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "curr_dir = os.getcwd()\n",
    "data_dir = curr_dir + '/../Data'\n",
    "solar_dir = data_dir + '/Solar'\n",
    "wind_dir = data_dir + '/Wind'\n",
    "price_dir = data_dir + '/Price'\n",
    "load_dir = data_dir + '/Load'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join('housing-data.csv'), header=None).values\n",
    "x = data[:, :-1]\n",
    "y = data[:, -1, None]\n",
    "train_idx = random.sample(range(len(x)), len(x)/2)\n",
    "test_idx = list(set(range(len(x))) - set(train_idx))\n",
    "x_train = x.take(train_idx, axis=0)\n",
    "x_test = x.take(test_idx, axis=0)\n",
    "y_train = y.take(train_idx, axis=0)\n",
    "y_test = y.take(test_idx, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def least_squares(x_train, y_train, x_test, intercept=True):\n",
    "    \"\"\"Compute the least squares predictions.\n",
    "    \n",
    "    :param x_train: Numpy array like of the training feature space.\n",
    "    :param y_train: Numpy array like of the training labels.\n",
    "    :param x_test: Numpy array like of the feature space to predict on.\n",
    "    :param intercept: Boolean indicating whether or not an intercept has been\n",
    "    added to the feature spaces yet.\n",
    "    \n",
    "    :return predictions: Numpy array of the predictions for the training data.\n",
    "    \"\"\"\n",
    "    \n",
    "    if intercept:\n",
    "        pass\n",
    "    else:\n",
    "        n_tr = len(x_train)\n",
    "        n_t = len(x_test)\n",
    "\n",
    "        x_train = np.hstack((np.ones((n_tr, 1)), x_train))\n",
    "        x_test = np.hstack((np.ones((x_t, 1)), x_test))\n",
    "    \n",
    "    beta = np.linalg.pinv(x_train.T.dot(x_train)).dot(x_train.T.dot(y_train))\n",
    "    \n",
    "    predictions = x_test.dot(beta)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstqr_hat_matrix(x_train, y_train, intercept=True):\n",
    "    \"\"\"Calculating the smoothing matrix S.\n",
    "    \n",
    "    :param x_train: Numpy array like of the training feature space.\n",
    "    :param y_train: Numpy array like of the training labels.\n",
    "    :param intercept: Boolean indicating whether or not an intercept has been\n",
    "    added to the feature spaces yet.\n",
    "    \n",
    "    :return hat_matrix: Numpy array of the smoothing matrix S for the model.\n",
    "    \"\"\"\n",
    "        \n",
    "    if intercept:\n",
    "        pass\n",
    "    else:\n",
    "        n_tr = len(x_train)\n",
    "        x_train = np.hstack((np.ones((n_tr, 1)), x_train))\n",
    "        \n",
    "    hat_matrix = x_train.dot(np.linalg.pinv(x_train.T.dot(x_train))).dot(x_train.T)\n",
    "    \n",
    "    return hat_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def efficient_LOOCV(x_train, y_train, learning_alg, smoothing_alg):\n",
    "    \"\"\"Compute the LOOCV for a training and testing set of data.\n",
    "    \n",
    "    :param x_train: Numpy array like of the feature space.\n",
    "    :param y_train: Numpy array like of the training labels.\n",
    "    :param learning_alg: Function to compute the predictions for the training \n",
    "    data. This learning algorithm must be a linear smoother.\n",
    "    :param smoothing_alg: Function to compute the smoothing matrix.\n",
    "    \n",
    "    :return loocv: The leave one out cross validation error.\n",
    "    \"\"\"\n",
    "    \n",
    "    n = float(len(x_train))\n",
    "    \n",
    "    hat_matrix = smoothing_alg(x_train, y_train)\n",
    "    hat_diag = np.diagonal(hat_matrix).reshape((-1,1))\n",
    "    \n",
    "    f_hat = learning_alg(x_train, y_train, x_train)\n",
    "    \n",
    "    residuals = y_train - f_hat\n",
    "    \n",
    "    smoothing = 1 - hat_diag\n",
    "\n",
    "    loocv_vector = residuals/smoothing\n",
    "\n",
    "    loocv = 1/n * np.dot(loocv_vector.T, loocv_vector)\n",
    "        \n",
    "    return float(loocv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_stepwise_selection_lm(x, y, q, learning_alg, smoothing_alg):\n",
    "    \"\"\"Choose features to use by forward stepwise selection for a linear model.\n",
    "    \n",
    "    :param x: Numpy array like of the feature space.\n",
    "    :param y: Numpy array like of the labels for the data.\n",
    "    :param q: Integer of the number of features to select.\n",
    "    :param learning_alg: Function to compute the predictions for the training \n",
    "    data. This learning algorithm must be a linear smoother.\n",
    "    :param smoothing_alg: Function to compute the smoothing matrix.\n",
    "    \n",
    "    :return x_prime: Numpy array of the new feature space selected.\n",
    "    :return j_prime: List of the indexes of the feature space that were kept.\n",
    "    \"\"\"\n",
    "    \n",
    "    n = x.shape[0]\n",
    "    p = x.shape[1]\n",
    "    \n",
    "    # Begin with an intercept term.    \n",
    "    x_prime = np.ones((n, 1))\n",
    "    j_prime = []\n",
    "    \n",
    "    for i in range(q):\n",
    "        \n",
    "        # Computing the loocv by adding each feature.\n",
    "        errors = [efficient_LOOCV(np.hstack((x_prime, x[:, j, None])), y, learning_alg, smoothing_alg) \n",
    "                  if j not in j_prime else float('inf') for j in xrange(p)] \n",
    "        \n",
    "        # Finding the feature index that minimized the loocv by adding the feature.\n",
    "        j_prime.append(np.argmin(np.array(errors)))\n",
    "\n",
    "        # Adding the best feature to the new feature vector to keep.\n",
    "        x_prime = np.hstack((x_prime, x[:, j_prime[-1], None]))\n",
    "    \n",
    "    x_prime = x_prime[:, 1:]\n",
    "    \n",
    "    return x_prime, j_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_prime, j_prime = forward_stepwise_selection_lm(x_train, y_train, 5, least_squares, lstqr_hat_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
